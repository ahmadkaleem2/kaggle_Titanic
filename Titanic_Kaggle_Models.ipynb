{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_Kaggle_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IcXv1tipJp4OBJAgmPS_O6OOck3Y3dcP",
      "authorship_tag": "ABX9TyOBd3fbs2W/uJ7qADZDL7cs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadkaleem2/kaggle_Titanic/blob/main/Titanic_Kaggle_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezcz08PTh152"
      },
      "source": [
        "Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygyuicEAn6XI"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import zipfile\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOX-iAOCh7K4"
      },
      "source": [
        "Importing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HSt3qSroFYF"
      },
      "source": [
        "data1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Titanic/train.csv')\n",
        "test_prediction1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Titanic/test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miPprJp4jxOc"
      },
      "source": [
        "How many people survived?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "ryUHoe5FiAXp",
        "outputId": "faf17e9b-360c-452c-9564-6b764f876382"
      },
      "source": [
        "\n",
        "sns.catplot('Survived',data = data1,kind='count',height=7.5,)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7faa3670dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 540x540 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4N3s4kpj7Pf"
      },
      "source": [
        "Extracting Relevant features and cleaning up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_AHdouasoNMA",
        "outputId": "eef88230-179a-4ede-db11-6345bac431d5"
      },
      "source": [
        "data1.describe()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QNdEZ484noL",
        "outputId": "583b5be6-17bd-466f-9006-d7d8b817fba6"
      },
      "source": [
        "data1.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "KogSNn4R4-Ej",
        "outputId": "04dbc729-4fca-42f4-ecf9-8cec56729a09"
      },
      "source": [
        "test_prediction1.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>418.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>332.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>417.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1100.500000</td>\n",
              "      <td>2.265550</td>\n",
              "      <td>30.272590</td>\n",
              "      <td>0.447368</td>\n",
              "      <td>0.392344</td>\n",
              "      <td>35.627188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>120.810458</td>\n",
              "      <td>0.841838</td>\n",
              "      <td>14.181209</td>\n",
              "      <td>0.896760</td>\n",
              "      <td>0.981429</td>\n",
              "      <td>55.907576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>892.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>996.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1100.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1204.750000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1309.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
              "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
              "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
              "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
              "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
              "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
              "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
              "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
              "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSFzN6sr5Bal",
        "outputId": "34b07f34-d833-47b3-bc61-aba9153c8999"
      },
      "source": [
        "test_prediction1.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "OgPbkICU4pLW",
        "outputId": "2689c6ec-cc47-4485-d644-8ae7304f2919"
      },
      "source": [
        "data1.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6gG7kIz4x48"
      },
      "source": [
        "data = data1.drop(['Fare','Cabin','Embarked','Name','Ticket','PassengerId'],axis=1)\n",
        "y = data['Survived']\n",
        "data = data.drop(['Survived'],axis=1)\n",
        "\n",
        "\n",
        "test_prediction = test_prediction1.drop(['Fare','Cabin','Embarked','Name','Ticket','PassengerId'],axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_V1WTlRLy1G"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "VdBS4ujv469i",
        "outputId": "98d0da8e-ccda-4615-ee7d-3642a23a54b3"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass     Sex   Age  SibSp  Parch\n",
              "0       3    male  22.0      1      0\n",
              "1       1  female  38.0      1      0\n",
              "2       3  female  26.0      0      0\n",
              "3       1  female  35.0      1      0\n",
              "4       3    male  35.0      0      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwWOqTau5MYN",
        "outputId": "2ac65d5b-4ea6-443c-c0b0-59de9aabf1d9"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Pclass  891 non-null    int64  \n",
            " 1   Sex     891 non-null    object \n",
            " 2   Age     714 non-null    float64\n",
            " 3   SibSp   891 non-null    int64  \n",
            " 4   Parch   891 non-null    int64  \n",
            "dtypes: float64(1), int64(3), object(1)\n",
            "memory usage: 34.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw47K1R9-npz",
        "outputId": "d168baee-8df7-44ce-a2bf-33776f4a305c"
      },
      "source": [
        "[col for col in data.columns if data[col].dtypes != 'object']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pclass', 'Age', 'SibSp', 'Parch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTm3x2JA743-"
      },
      "source": [
        "cat_cols = [col for col in data.columns if data[col].dtypes == 'object']\n",
        "numerical_cols = [col for col in data.columns if data[col].dtypes != 'object']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "OaLi_ikQDEXB",
        "outputId": "1c8bdd5d-2748-4933-8000-486a7042e86a"
      },
      "source": [
        "data"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex   Age  SibSp  Parch\n",
              "0         3    male  22.0      1      0\n",
              "1         1  female  38.0      1      0\n",
              "2         3  female  26.0      0      0\n",
              "3         1  female  35.0      1      0\n",
              "4         3    male  35.0      0      0\n",
              "..      ...     ...   ...    ...    ...\n",
              "886       2    male  27.0      0      0\n",
              "887       1  female  19.0      0      0\n",
              "888       3  female   NaN      1      2\n",
              "889       1    male  26.0      0      0\n",
              "890       3    male  32.0      0      0\n",
              "\n",
              "[891 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiNegYLEQEej",
        "outputId": "b5701ceb-bee3-4372-b8d3-5e814c324173"
      },
      "source": [
        "cat_cols"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sex']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvyuY7UGkLFb"
      },
      "source": [
        "making a pipeline for cleaning dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VzIw-_F5OuM"
      },
      "source": [
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('Imp',SimpleImputer(strategy='median')),\n",
        "    \n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "                                          ('Imp1',SimpleImputer(missing_values=np.NaN,strategy='most_frequent')),\n",
        "                                          ('onehot',OneHotEncoder())\n",
        "])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "                                               ('num',numerical_transformer,numerical_cols),\n",
        "                                               ('cat',categorical_transformer,cat_cols)\n",
        "                                               ])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "X0XceU6jQMMi",
        "outputId": "e4a61e5d-53e4-4475-e15a-562b3c46ed15"
      },
      "source": [
        "data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex   Age  SibSp  Parch\n",
              "0         3    male  22.0      1      0\n",
              "1         1  female  38.0      1      0\n",
              "2         3  female  26.0      0      0\n",
              "3         1  female  35.0      1      0\n",
              "4         3    male  35.0      0      0\n",
              "..      ...     ...   ...    ...    ...\n",
              "886       2    male  27.0      0      0\n",
              "887       1  female  19.0      0      0\n",
              "888       3  female   NaN      1      2\n",
              "889       1    male  26.0      0      0\n",
              "890       3    male  32.0      0      0\n",
              "\n",
              "[891 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1aGwkDZXCm6"
      },
      "source": [
        "numerical_cols1 = numerical_cols.copy()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W5HshxMXO5z",
        "outputId": "2ec6bf56-47af-4a1e-c406-2980dc673c51"
      },
      "source": [
        "numerical_cols1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pclass', 'Age', 'SibSp', 'Parch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Br-5jTnW7e1E",
        "outputId": "e76d68f1-15af-4a81-cc84-697164836502"
      },
      "source": [
        "processed_data = pd.DataFrame(preprocessor.fit_transform(data))\n",
        "\n",
        "numerical_cols1.append('Sex_Female')\n",
        "numerical_cols1.append('Sex_male')\n",
        "processed_data.columns = numerical_cols1\n",
        "processed_data"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_Female</th>\n",
              "      <th>Sex_male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass   Age  SibSp  Parch  Sex_Female  Sex_male\n",
              "0       3.0  22.0    1.0    0.0         0.0       1.0\n",
              "1       1.0  38.0    1.0    0.0         1.0       0.0\n",
              "2       3.0  26.0    0.0    0.0         1.0       0.0\n",
              "3       1.0  35.0    1.0    0.0         1.0       0.0\n",
              "4       3.0  35.0    0.0    0.0         0.0       1.0\n",
              "..      ...   ...    ...    ...         ...       ...\n",
              "886     2.0  27.0    0.0    0.0         0.0       1.0\n",
              "887     1.0  19.0    0.0    0.0         1.0       0.0\n",
              "888     3.0  28.0    1.0    2.0         1.0       0.0\n",
              "889     1.0  26.0    0.0    0.0         0.0       1.0\n",
              "890     3.0  32.0    0.0    0.0         0.0       1.0\n",
              "\n",
              "[891 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwQucc4wkkXk"
      },
      "source": [
        "Removing redundant feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKDtK0Qb8V5a"
      },
      "source": [
        "processed_data = processed_data.drop('Sex_Female',axis=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXWXGH9F8ybA"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DifG9fbCkvSF"
      },
      "source": [
        "Adding column 'is_child' children have more probability of surviving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbN2JKREDeDC"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "age_fare = scaler.fit_transform(processed_data[['Age']])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT7G5US2Dwrf"
      },
      "source": [
        "age_fare = pd.DataFrame(age_fare)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQbkALA0EL3c"
      },
      "source": [
        "age_fare.columns = ['Age',]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xy35oSIUIk-G",
        "outputId": "59730edc-3b55-4e9e-e6ab-ed715c837a7b"
      },
      "source": [
        "processed_data['is_child']= [1 if processed_data['Age'][i]<16 else 0 for i in processed_data.index]\n",
        "processed_data[0:50]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>is_child</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>3.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Pclass   Age  SibSp  Parch  Sex_male  is_child\n",
              "0      3.0  22.0    1.0    0.0       1.0         0\n",
              "1      1.0  38.0    1.0    0.0       0.0         0\n",
              "2      3.0  26.0    0.0    0.0       0.0         0\n",
              "3      1.0  35.0    1.0    0.0       0.0         0\n",
              "4      3.0  35.0    0.0    0.0       1.0         0\n",
              "5      3.0  28.0    0.0    0.0       1.0         0\n",
              "6      1.0  54.0    0.0    0.0       1.0         0\n",
              "7      3.0   2.0    3.0    1.0       1.0         1\n",
              "8      3.0  27.0    0.0    2.0       0.0         0\n",
              "9      2.0  14.0    1.0    0.0       0.0         1\n",
              "10     3.0   4.0    1.0    1.0       0.0         1\n",
              "11     1.0  58.0    0.0    0.0       0.0         0\n",
              "12     3.0  20.0    0.0    0.0       1.0         0\n",
              "13     3.0  39.0    1.0    5.0       1.0         0\n",
              "14     3.0  14.0    0.0    0.0       0.0         1\n",
              "15     2.0  55.0    0.0    0.0       0.0         0\n",
              "16     3.0   2.0    4.0    1.0       1.0         1\n",
              "17     2.0  28.0    0.0    0.0       1.0         0\n",
              "18     3.0  31.0    1.0    0.0       0.0         0\n",
              "19     3.0  28.0    0.0    0.0       0.0         0\n",
              "20     2.0  35.0    0.0    0.0       1.0         0\n",
              "21     2.0  34.0    0.0    0.0       1.0         0\n",
              "22     3.0  15.0    0.0    0.0       0.0         1\n",
              "23     1.0  28.0    0.0    0.0       1.0         0\n",
              "24     3.0   8.0    3.0    1.0       0.0         1\n",
              "25     3.0  38.0    1.0    5.0       0.0         0\n",
              "26     3.0  28.0    0.0    0.0       1.0         0\n",
              "27     1.0  19.0    3.0    2.0       1.0         0\n",
              "28     3.0  28.0    0.0    0.0       0.0         0\n",
              "29     3.0  28.0    0.0    0.0       1.0         0\n",
              "30     1.0  40.0    0.0    0.0       1.0         0\n",
              "31     1.0  28.0    1.0    0.0       0.0         0\n",
              "32     3.0  28.0    0.0    0.0       0.0         0\n",
              "33     2.0  66.0    0.0    0.0       1.0         0\n",
              "34     1.0  28.0    1.0    0.0       1.0         0\n",
              "35     1.0  42.0    1.0    0.0       1.0         0\n",
              "36     3.0  28.0    0.0    0.0       1.0         0\n",
              "37     3.0  21.0    0.0    0.0       1.0         0\n",
              "38     3.0  18.0    2.0    0.0       0.0         0\n",
              "39     3.0  14.0    1.0    0.0       0.0         1\n",
              "40     3.0  40.0    1.0    0.0       0.0         0\n",
              "41     2.0  27.0    1.0    0.0       0.0         0\n",
              "42     3.0  28.0    0.0    0.0       1.0         0\n",
              "43     2.0   3.0    1.0    2.0       0.0         1\n",
              "44     3.0  19.0    0.0    0.0       0.0         0\n",
              "45     3.0  28.0    0.0    0.0       1.0         0\n",
              "46     3.0  28.0    1.0    0.0       1.0         0\n",
              "47     3.0  28.0    0.0    0.0       0.0         0\n",
              "48     3.0  28.0    2.0    0.0       1.0         0\n",
              "49     3.0  18.0    1.0    0.0       0.0         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrleH4vgHcr4"
      },
      "source": [
        "\n",
        "processed_data = processed_data.drop(['Age',],axis=1)\n",
        "frames = [processed_data,age_fare]\n",
        "processed_data = pd.concat(frames,axis=1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "KqN7k5PvE23i",
        "outputId": "7a598aa3-68cc-4f01-a61c-dfaa064319de"
      },
      "source": [
        "processed_data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>is_child</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.334004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.233476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.396833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  SibSp  Parch  Sex_male  is_child       Age\n",
              "0       3.0    1.0    0.0       1.0         0  0.271174\n",
              "1       1.0    1.0    0.0       0.0         0  0.472229\n",
              "2       3.0    0.0    0.0       0.0         0  0.321438\n",
              "3       1.0    1.0    0.0       0.0         0  0.434531\n",
              "4       3.0    0.0    0.0       1.0         0  0.434531\n",
              "..      ...    ...    ...       ...       ...       ...\n",
              "886     2.0    0.0    0.0       1.0         0  0.334004\n",
              "887     1.0    0.0    0.0       0.0         0  0.233476\n",
              "888     3.0    1.0    2.0       0.0         0  0.346569\n",
              "889     1.0    0.0    0.0       1.0         0  0.321438\n",
              "890     3.0    0.0    0.0       1.0         0  0.396833\n",
              "\n",
              "[891 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSicdqyQHBtp",
        "outputId": "bb5d7d1f-bf75-4f76-b643-090f639b8a24"
      },
      "source": [
        "processed_data.info()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Pclass    891 non-null    float64\n",
            " 1   SibSp     891 non-null    float64\n",
            " 2   Parch     891 non-null    float64\n",
            " 3   Sex_male  891 non-null    float64\n",
            " 4   is_child  891 non-null    int64  \n",
            " 5   Age       891 non-null    float64\n",
            "dtypes: float64(5), int64(1)\n",
            "memory usage: 41.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj_6yzf-X1uK"
      },
      "source": [
        "Adding addition columns which might improve accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWaxLiiWIlub"
      },
      "source": [
        "processed_data['is_Alone']= [1 if processed_data['SibSp'][i]>0 or processed_data['Parch'][i]>0 else 0 for i in processed_data.index]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "hDZkr8gsJKgz",
        "outputId": "960c1c45-18b0-4b64-c0bd-f9c479aa440a"
      },
      "source": [
        "processed_data"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>is_child</th>\n",
              "      <th>Age</th>\n",
              "      <th>is_Alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346569</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  SibSp  Parch  Sex_male  is_child       Age  is_Alone\n",
              "0       3.0    1.0    0.0       1.0         0  0.271174         1\n",
              "1       1.0    1.0    0.0       0.0         0  0.472229         1\n",
              "2       3.0    0.0    0.0       0.0         0  0.321438         0\n",
              "3       1.0    1.0    0.0       0.0         0  0.434531         1\n",
              "4       3.0    0.0    0.0       1.0         0  0.434531         0\n",
              "..      ...    ...    ...       ...       ...       ...       ...\n",
              "886     2.0    0.0    0.0       1.0         0  0.334004         0\n",
              "887     1.0    0.0    0.0       0.0         0  0.233476         0\n",
              "888     3.0    1.0    2.0       0.0         0  0.346569         1\n",
              "889     1.0    0.0    0.0       1.0         0  0.321438         0\n",
              "890     3.0    0.0    0.0       1.0         0  0.396833         0\n",
              "\n",
              "[891 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR5jSJiR6dyO"
      },
      "source": [
        "X = processed_data"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "QUW63rbHLAfG",
        "outputId": "2b9d6b72-5bb6-44c6-f3b0-6bd522bf874a"
      },
      "source": [
        "X"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>is_child</th>\n",
              "      <th>Age</th>\n",
              "      <th>is_Alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346569</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  SibSp  Parch  Sex_male  is_child       Age  is_Alone\n",
              "0       3.0    1.0    0.0       1.0         0  0.271174         1\n",
              "1       1.0    1.0    0.0       0.0         0  0.472229         1\n",
              "2       3.0    0.0    0.0       0.0         0  0.321438         0\n",
              "3       1.0    1.0    0.0       0.0         0  0.434531         1\n",
              "4       3.0    0.0    0.0       1.0         0  0.434531         0\n",
              "..      ...    ...    ...       ...       ...       ...       ...\n",
              "886     2.0    0.0    0.0       1.0         0  0.334004         0\n",
              "887     1.0    0.0    0.0       0.0         0  0.233476         0\n",
              "888     3.0    1.0    2.0       0.0         0  0.346569         1\n",
              "889     1.0    0.0    0.0       1.0         0  0.321438         0\n",
              "890     3.0    0.0    0.0       1.0         0  0.396833         0\n",
              "\n",
              "[891 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSHdLAFt61dd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beM-haIBX-jM"
      },
      "source": [
        "Making models (DecisonTree,RandomForest,LogisticRegression,SGDClassifier,XGBClassifier,Naive Bayes, Linear SVM,SVC,Gaussian Classifier,KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivQ8ESBzjg3E"
      },
      "source": [
        "![Capture.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh82hq_H7E2J",
        "outputId": "e3214366-1aad-418f-bf24-393bbe94a9b1"
      },
      "source": [
        "Decision_model = DecisionTreeClassifier(random_state=42,max_depth=10)\n",
        "Decision_model.fit(X_train,y_train)\n",
        "accuracy_score(y_test,Decision_model.predict(X_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7627118644067796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q3kGndPd6Gu",
        "outputId": "c630750c-5cb3-41c2-db55-5a8b52532289"
      },
      "source": [
        "random_forest_model = RandomForestClassifier(n_estimators=50,random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "accuracy_score(y_test,random_forest_model.predict(X_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8271186440677966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YCfVA1wl6av",
        "outputId": "5555cc92-8825-4098-9202-75ec622eeb66"
      },
      "source": [
        "logmodel = LogisticRegression(max_iter=10,random_state=42,penalty='l2',verbose=0)\n",
        "\n",
        "logmodel.fit(X_train,y_train)\n",
        "print(accuracy_score(y_test,logmodel.predict(X_test)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8338983050847457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WHFy6tQbzh-",
        "outputId": "e7502ad8-964a-4878-b36c-127bf2f773b9"
      },
      "source": [
        "sgd_model = SGDClassifier(random_state=42,max_iter=30,)\n",
        "\n",
        "sgd_model.fit(X_train,y_train)\n",
        "print(accuracy_score(y_test,sgd_model.predict(X_test)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn59-rEhbzgT",
        "outputId": "facc7d40-e58d-43cf-a2c8-8ba2f88996d0"
      },
      "source": [
        "xgb_model = XGBClassifier(random_state=42,n_estimators=80)\n",
        "\n",
        "xgb_model.fit(X_train,y_train)\n",
        "print(accuracy_score(y_test,xgb_model.predict(X_test)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8406779661016949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKe5sFAFbzeT",
        "outputId": "1420e79c-b035-4b56-9570-311e5a8ab847"
      },
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train,y_train)\n",
        "print(accuracy_score(y_test,nb_model.predict(X_test)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8203389830508474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llN_GYv0bzcI",
        "outputId": "e8575b45-dc15-492d-b74f-7910259e48da"
      },
      "source": [
        "svc_model = SVC(random_state=42,probability=True,max_iter=180)\n",
        "svc_model.fit(X_train,y_train)\n",
        "print(accuracy_score(y_test,svc_model.predict(X_test)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8406779661016949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=180).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUnb5EF5f6Ep",
        "outputId": "f14889ec-dc25-402e-f5fa-cb2bbea5f4a5"
      },
      "source": [
        "linearsvm = svm.LinearSVC(random_state=42,max_iter=300,)\n",
        "linearsvm.fit(X_train,y_train)\n",
        "print(accuracy_score(y_test,linearsvm.predict(X_test)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.823728813559322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnHw_QE5f6B2",
        "outputId": "624e2ed6-6216-4180-f94f-9d2098250a7b"
      },
      "source": [
        "gpc_model = GaussianProcessClassifier(random_state=42,max_iter_predict=5)\n",
        "\n",
        "gpc_model.fit(X_train,y_train)\n",
        "print(accuracy_score(y_test,gpc_model.predict(X_test)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8338983050847457\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqugsn5Epavy",
        "outputId": "05fd92cc-11d9-46b6-d40e-0df3d5351f14"
      },
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=2,leaf_size=40)\n",
        "knn_model.fit(X_train,y_train)\n",
        "print(accuracy_score(y_test,knn_model.predict(X_test)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oLT4S40qVVI"
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8ngE2o0qVS6"
      },
      "source": [
        "models = [knn_model,gpc_model,linearsvm,svc_model,nb_model,xgb_model,sgd_model,logmodel,random_forest_model,Decision_model]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shFH-IeoqVNg",
        "outputId": "6f10cd56-d591-4b9b-9f50-c31d46ad796a"
      },
      "source": [
        "accuracy = np.zeros((5,len(models)))\n",
        "for i in range(len(models)):\n",
        "  models[i].fit(X_train,y_train)\n",
        "  accuracy[:,i] = (cross_val_score(models[i],X,y,cv=5))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=180).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=180).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=180).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=180).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=180).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=180).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1OXSY2Ai-qp"
      },
      "source": [
        "Accuracy of each model on 5-folds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFvFVCGNqVGv"
      },
      "source": [
        "all_accuracy = pd.DataFrame(accuracy,columns=['knn_model','gpc_model','linearsvm','svc_model','nb_model','xgb_model','sgd_model','logmodel','random_forest_model','Decision_model'])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "h19fMMtZ1-nA",
        "outputId": "ce7d84f6-76be-4ddb-cd12-7c440304b7b5"
      },
      "source": [
        "all_accuracy"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>knn_model</th>\n",
              "      <th>gpc_model</th>\n",
              "      <th>linearsvm</th>\n",
              "      <th>svc_model</th>\n",
              "      <th>nb_model</th>\n",
              "      <th>xgb_model</th>\n",
              "      <th>sgd_model</th>\n",
              "      <th>logmodel</th>\n",
              "      <th>random_forest_model</th>\n",
              "      <th>Decision_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.720670</td>\n",
              "      <td>0.793296</td>\n",
              "      <td>0.815642</td>\n",
              "      <td>0.837989</td>\n",
              "      <td>0.759777</td>\n",
              "      <td>0.804469</td>\n",
              "      <td>0.709497</td>\n",
              "      <td>0.782123</td>\n",
              "      <td>0.759777</td>\n",
              "      <td>0.804469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.764045</td>\n",
              "      <td>0.797753</td>\n",
              "      <td>0.803371</td>\n",
              "      <td>0.814607</td>\n",
              "      <td>0.797753</td>\n",
              "      <td>0.814607</td>\n",
              "      <td>0.421348</td>\n",
              "      <td>0.797753</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.803371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.820225</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.825843</td>\n",
              "      <td>0.820225</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.404494</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.837079</td>\n",
              "      <td>0.808989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.780899</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.769663</td>\n",
              "      <td>0.803371</td>\n",
              "      <td>0.775281</td>\n",
              "      <td>0.797753</td>\n",
              "      <td>0.466292</td>\n",
              "      <td>0.769663</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.769663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.853933</td>\n",
              "      <td>0.825843</td>\n",
              "      <td>0.848315</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.848315</td>\n",
              "      <td>0.730337</td>\n",
              "      <td>0.842697</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.820225</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   knn_model  gpc_model  ...  random_forest_model  Decision_model\n",
              "0   0.720670   0.793296  ...             0.759777        0.804469\n",
              "1   0.764045   0.797753  ...             0.808989        0.803371\n",
              "2   0.831461   0.820225  ...             0.837079        0.808989\n",
              "3   0.780899   0.808989  ...             0.808989        0.769663\n",
              "4   0.808989   0.853933  ...             0.831461        0.820225\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjdbPALBPgq_",
        "outputId": "abfe1691-a97e-4544-e740-736812db0aba"
      },
      "source": [
        "models"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[KNeighborsClassifier(algorithm='auto', leaf_size=40, metric='minkowski',\n",
              "                      metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
              "                      weights='uniform'),\n",
              " GaussianProcessClassifier(copy_X_train=True, kernel=None, max_iter_predict=5,\n",
              "                           multi_class='one_vs_rest', n_jobs=None,\n",
              "                           n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
              "                           random_state=42, warm_start=False),\n",
              " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "           intercept_scaling=1, loss='squared_hinge', max_iter=300,\n",
              "           multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
              "           verbose=0),\n",
              " SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "     max_iter=180, probability=True, random_state=42, shrinking=True, tol=0.001,\n",
              "     verbose=False),\n",
              " GaussianNB(priors=None, var_smoothing=1e-09),\n",
              " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "               colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "               learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "               min_child_weight=1, missing=None, n_estimators=80, n_jobs=1,\n",
              "               nthread=None, objective='binary:logistic', random_state=42,\n",
              "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "               silent=None, subsample=1, verbosity=1),\n",
              " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "               l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=30,\n",
              "               n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
              "               random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
              "               verbose=0, warm_start=False),\n",
              " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                    intercept_scaling=1, l1_ratio=None, max_iter=10,\n",
              "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                    random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                    warm_start=False),\n",
              " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                        n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                        warm_start=False),\n",
              " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                        max_depth=10, max_features=None, max_leaf_nodes=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                        random_state=42, splitter='best')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sby0jNRjISA"
      },
      "source": [
        "Combining all models to check if accuracy improves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hErwr3sJLY3_"
      },
      "source": [
        "models = [knn_model,gpc_model,svc_model,nb_model,xgb_model,logmodel,random_forest_model,Decision_model]\n",
        "def get_prob(models,X_test):\n",
        "  prob = np.zeros((X_test.shape[0],len(models)))\n",
        "  for i in range(len(models)):\n",
        "    \n",
        "    prob[:,i] = models[i].predict_proba(X_test)[:,1]\n",
        "  return prob\n",
        "    "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5ccMC16POk7"
      },
      "source": [
        "probs = get_prob(models,X_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcQzZfiGZNKQ",
        "outputId": "81c2f7d9-d8f1-4b4a-89dd-ad8f4d9d6f60"
      },
      "source": [
        "probs.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(295, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etg42T2cQrjU",
        "outputId": "37862c3d-48f6-413d-ec5b-3bfc75c250fe"
      },
      "source": [
        "probs"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.21427177, 0.16308582, ..., 0.09502156, 0.1       ,\n",
              "        0.        ],\n",
              "       [0.        , 0.16366944, 0.16359064, ..., 0.21690538, 0.04766667,\n",
              "        0.        ],\n",
              "       [0.        , 0.14813835, 0.17463479, ..., 0.10858949, 0.        ,\n",
              "        0.15068493],\n",
              "       ...,\n",
              "       [0.5       , 0.65896022, 0.88482587, ..., 0.87731   , 0.71833333,\n",
              "        0.5       ],\n",
              "       [0.5       , 0.6275968 , 0.69646645, ..., 0.60149271, 0.34636364,\n",
              "        0.62857143],\n",
              "       [0.        , 0.14721163, 0.17435214, ..., 0.1084106 , 0.12141048,\n",
              "        0.15068493]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqkALlYAS5u-",
        "outputId": "ef8d7f72-1d68-4cbf-aa62-b7275b0ecedc"
      },
      "source": [
        "survived_pass = []\n",
        "for x in probs:\n",
        "  count=0\n",
        "  for i in x:\n",
        "    if i>0.5:\n",
        "      count+=1\n",
        "  if count>=4:\n",
        "    survived_pass.append(1)\n",
        "  else:\n",
        "    survived_pass.append(0)\n",
        "\n",
        "survived_pass"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd5g4V2hT7fn",
        "outputId": "23e6e025-aac6-4300-e8f3-a27dc56e2e50"
      },
      "source": [
        "print(accuracy_score(y_test,survived_pass))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8440677966101695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WuQQqYkf5-1",
        "outputId": "2f7057cd-65f8-40cf-8f42-112a1782e46a"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)\n",
        "model_1 = tf.keras.Sequential([\n",
        "                               \n",
        "                               tf.keras.layers.Dense(50),\n",
        "                              tf.keras.layers.Dense(25,),\n",
        "                       \n",
        "                   \n",
        "                     tf.keras.layers.Dense(20,'tanh'),\n",
        "                     tf.keras.layers.Dense(10,'tanh'),\n",
        "                     tf.keras.layers.Dense(1,'sigmoid')\n",
        "])\n",
        "\n",
        "def lr_reduce(epoch, lr):\n",
        "  if epoch>100:\n",
        "    lr * 0.95\n",
        "  return lr\n",
        "  \n",
        "\n",
        "\n",
        "lr_sched = tf.keras.callbacks.LearningRateScheduler(lr_reduce)\n",
        "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
        "model_1.fit(X_train,y_train,epochs=300,validation_data=(X_test,y_test),callbacks=[lr_sched])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "19/19 [==============================] - 1s 13ms/step - loss: 0.6379 - accuracy: 0.6174 - val_loss: 0.5853 - val_accuracy: 0.6576\n",
            "Epoch 2/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7282 - val_loss: 0.5309 - val_accuracy: 0.7492\n",
            "Epoch 3/300\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.7668 - val_loss: 0.4947 - val_accuracy: 0.8034\n",
            "Epoch 4/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7936 - val_loss: 0.4708 - val_accuracy: 0.8169\n",
            "Epoch 5/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7970 - val_loss: 0.4562 - val_accuracy: 0.8169\n",
            "Epoch 6/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7936 - val_loss: 0.4549 - val_accuracy: 0.8102\n",
            "Epoch 7/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7903 - val_loss: 0.4437 - val_accuracy: 0.8203\n",
            "Epoch 8/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8037 - val_loss: 0.4430 - val_accuracy: 0.8034\n",
            "Epoch 9/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.8003 - val_loss: 0.4350 - val_accuracy: 0.8169\n",
            "Epoch 10/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.8003 - val_loss: 0.4334 - val_accuracy: 0.8203\n",
            "Epoch 11/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.8037 - val_loss: 0.4328 - val_accuracy: 0.8203\n",
            "Epoch 12/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.8070 - val_loss: 0.4342 - val_accuracy: 0.8102\n",
            "Epoch 13/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8054 - val_loss: 0.4285 - val_accuracy: 0.8271\n",
            "Epoch 14/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8003 - val_loss: 0.4266 - val_accuracy: 0.8237\n",
            "Epoch 15/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.8070 - val_loss: 0.4243 - val_accuracy: 0.8203\n",
            "Epoch 16/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.8087 - val_loss: 0.4250 - val_accuracy: 0.8271\n",
            "Epoch 17/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8171 - val_loss: 0.4226 - val_accuracy: 0.8136\n",
            "Epoch 18/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8087 - val_loss: 0.4203 - val_accuracy: 0.8271\n",
            "Epoch 19/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8138 - val_loss: 0.4201 - val_accuracy: 0.8203\n",
            "Epoch 20/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8171 - val_loss: 0.4187 - val_accuracy: 0.8136\n",
            "Epoch 21/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8104 - val_loss: 0.4197 - val_accuracy: 0.8237\n",
            "Epoch 22/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8070 - val_loss: 0.4164 - val_accuracy: 0.8237\n",
            "Epoch 23/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8087 - val_loss: 0.4145 - val_accuracy: 0.8271\n",
            "Epoch 24/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8171 - val_loss: 0.4161 - val_accuracy: 0.7932\n",
            "Epoch 25/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8054 - val_loss: 0.4145 - val_accuracy: 0.8305\n",
            "Epoch 26/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8087 - val_loss: 0.4166 - val_accuracy: 0.8237\n",
            "Epoch 27/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8138 - val_loss: 0.4112 - val_accuracy: 0.8237\n",
            "Epoch 28/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8138 - val_loss: 0.4108 - val_accuracy: 0.8271\n",
            "Epoch 29/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8188 - val_loss: 0.4112 - val_accuracy: 0.8271\n",
            "Epoch 30/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8171 - val_loss: 0.4109 - val_accuracy: 0.8203\n",
            "Epoch 31/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8205 - val_loss: 0.4113 - val_accuracy: 0.8237\n",
            "Epoch 32/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8154 - val_loss: 0.4111 - val_accuracy: 0.8169\n",
            "Epoch 33/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8138 - val_loss: 0.4093 - val_accuracy: 0.8136\n",
            "Epoch 34/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8205 - val_loss: 0.4118 - val_accuracy: 0.8305\n",
            "Epoch 35/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8171 - val_loss: 0.4108 - val_accuracy: 0.8271\n",
            "Epoch 36/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8221 - val_loss: 0.4086 - val_accuracy: 0.8271\n",
            "Epoch 37/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8104 - val_loss: 0.4080 - val_accuracy: 0.8203\n",
            "Epoch 38/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8238 - val_loss: 0.4119 - val_accuracy: 0.8237\n",
            "Epoch 39/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8154 - val_loss: 0.4080 - val_accuracy: 0.8068\n",
            "Epoch 40/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8188 - val_loss: 0.4063 - val_accuracy: 0.8305\n",
            "Epoch 41/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8255 - val_loss: 0.4065 - val_accuracy: 0.8237\n",
            "Epoch 42/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8104 - val_loss: 0.4056 - val_accuracy: 0.8068\n",
            "Epoch 43/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8255 - val_loss: 0.4122 - val_accuracy: 0.8271\n",
            "Epoch 44/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8238 - val_loss: 0.4053 - val_accuracy: 0.8034\n",
            "Epoch 45/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8205 - val_loss: 0.4089 - val_accuracy: 0.8305\n",
            "Epoch 46/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8238 - val_loss: 0.4053 - val_accuracy: 0.8068\n",
            "Epoch 47/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8221 - val_loss: 0.4075 - val_accuracy: 0.8237\n",
            "Epoch 48/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8171 - val_loss: 0.4065 - val_accuracy: 0.8305\n",
            "Epoch 49/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8171 - val_loss: 0.4054 - val_accuracy: 0.8237\n",
            "Epoch 50/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8272 - val_loss: 0.4070 - val_accuracy: 0.8136\n",
            "Epoch 51/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8104 - val_loss: 0.4083 - val_accuracy: 0.8034\n",
            "Epoch 52/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8154 - val_loss: 0.4068 - val_accuracy: 0.8271\n",
            "Epoch 53/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8221 - val_loss: 0.4071 - val_accuracy: 0.8271\n",
            "Epoch 54/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8221 - val_loss: 0.4066 - val_accuracy: 0.8237\n",
            "Epoch 55/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8138 - val_loss: 0.4085 - val_accuracy: 0.8136\n",
            "Epoch 56/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8255 - val_loss: 0.4096 - val_accuracy: 0.8237\n",
            "Epoch 57/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8154 - val_loss: 0.4074 - val_accuracy: 0.8373\n",
            "Epoch 58/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8205 - val_loss: 0.4077 - val_accuracy: 0.8305\n",
            "Epoch 59/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8104 - val_loss: 0.4080 - val_accuracy: 0.8136\n",
            "Epoch 60/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8154 - val_loss: 0.4073 - val_accuracy: 0.8305\n",
            "Epoch 61/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8272 - val_loss: 0.4063 - val_accuracy: 0.8136\n",
            "Epoch 62/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8221 - val_loss: 0.4099 - val_accuracy: 0.8271\n",
            "Epoch 63/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8221 - val_loss: 0.4058 - val_accuracy: 0.8407\n",
            "Epoch 64/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8255 - val_loss: 0.4091 - val_accuracy: 0.8339\n",
            "Epoch 65/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8104 - val_loss: 0.4080 - val_accuracy: 0.8339\n",
            "Epoch 66/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8238 - val_loss: 0.4058 - val_accuracy: 0.8102\n",
            "Epoch 67/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8188 - val_loss: 0.4137 - val_accuracy: 0.8034\n",
            "Epoch 68/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8104 - val_loss: 0.4046 - val_accuracy: 0.8441\n",
            "Epoch 69/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8238 - val_loss: 0.4100 - val_accuracy: 0.8407\n",
            "Epoch 70/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8188 - val_loss: 0.4075 - val_accuracy: 0.8034\n",
            "Epoch 71/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8221 - val_loss: 0.4110 - val_accuracy: 0.8237\n",
            "Epoch 72/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8272 - val_loss: 0.4083 - val_accuracy: 0.8441\n",
            "Epoch 73/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8171 - val_loss: 0.4101 - val_accuracy: 0.8373\n",
            "Epoch 74/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8104 - val_loss: 0.4107 - val_accuracy: 0.8339\n",
            "Epoch 75/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8238 - val_loss: 0.4053 - val_accuracy: 0.8102\n",
            "Epoch 76/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8322 - val_loss: 0.4111 - val_accuracy: 0.8373\n",
            "Epoch 77/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8188 - val_loss: 0.4114 - val_accuracy: 0.8373\n",
            "Epoch 78/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8289 - val_loss: 0.4086 - val_accuracy: 0.8407\n",
            "Epoch 79/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8305 - val_loss: 0.4111 - val_accuracy: 0.8373\n",
            "Epoch 80/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8305 - val_loss: 0.4086 - val_accuracy: 0.8271\n",
            "Epoch 81/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8171 - val_loss: 0.4095 - val_accuracy: 0.8068\n",
            "Epoch 82/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8255 - val_loss: 0.4076 - val_accuracy: 0.8373\n",
            "Epoch 83/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8322 - val_loss: 0.4120 - val_accuracy: 0.8203\n",
            "Epoch 84/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8238 - val_loss: 0.4132 - val_accuracy: 0.8373\n",
            "Epoch 85/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8305 - val_loss: 0.4101 - val_accuracy: 0.8271\n",
            "Epoch 86/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8238 - val_loss: 0.4129 - val_accuracy: 0.8339\n",
            "Epoch 87/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8255 - val_loss: 0.4106 - val_accuracy: 0.8102\n",
            "Epoch 88/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8238 - val_loss: 0.4122 - val_accuracy: 0.8339\n",
            "Epoch 89/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8289 - val_loss: 0.4123 - val_accuracy: 0.8373\n",
            "Epoch 90/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8372 - val_loss: 0.4138 - val_accuracy: 0.8373\n",
            "Epoch 91/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8372 - val_loss: 0.4102 - val_accuracy: 0.8068\n",
            "Epoch 92/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8238 - val_loss: 0.4159 - val_accuracy: 0.8305\n",
            "Epoch 93/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8289 - val_loss: 0.4138 - val_accuracy: 0.8407\n",
            "Epoch 94/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8322 - val_loss: 0.4164 - val_accuracy: 0.8373\n",
            "Epoch 95/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8322 - val_loss: 0.4103 - val_accuracy: 0.8102\n",
            "Epoch 96/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8154 - val_loss: 0.4198 - val_accuracy: 0.8339\n",
            "Epoch 97/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8389 - val_loss: 0.4087 - val_accuracy: 0.8102\n",
            "Epoch 98/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8305 - val_loss: 0.4153 - val_accuracy: 0.8373\n",
            "Epoch 99/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8238 - val_loss: 0.4170 - val_accuracy: 0.8407\n",
            "Epoch 100/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8322 - val_loss: 0.4126 - val_accuracy: 0.8068\n",
            "Epoch 101/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8205 - val_loss: 0.4161 - val_accuracy: 0.8407\n",
            "Epoch 102/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8238 - val_loss: 0.4166 - val_accuracy: 0.8407\n",
            "Epoch 103/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8272 - val_loss: 0.4197 - val_accuracy: 0.8339\n",
            "Epoch 104/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8221 - val_loss: 0.4139 - val_accuracy: 0.8102\n",
            "Epoch 105/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8221 - val_loss: 0.4156 - val_accuracy: 0.8407\n",
            "Epoch 106/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8205 - val_loss: 0.4182 - val_accuracy: 0.8237\n",
            "Epoch 107/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8289 - val_loss: 0.4131 - val_accuracy: 0.8407\n",
            "Epoch 108/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8322 - val_loss: 0.4205 - val_accuracy: 0.8373\n",
            "Epoch 109/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8272 - val_loss: 0.4107 - val_accuracy: 0.8102\n",
            "Epoch 110/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8221 - val_loss: 0.4146 - val_accuracy: 0.8373\n",
            "Epoch 111/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8272 - val_loss: 0.4114 - val_accuracy: 0.8407\n",
            "Epoch 112/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8289 - val_loss: 0.4175 - val_accuracy: 0.8373\n",
            "Epoch 113/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8272 - val_loss: 0.4150 - val_accuracy: 0.8034\n",
            "Epoch 114/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8322 - val_loss: 0.4170 - val_accuracy: 0.8407\n",
            "Epoch 115/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8272 - val_loss: 0.4220 - val_accuracy: 0.8373\n",
            "Epoch 116/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8305 - val_loss: 0.4135 - val_accuracy: 0.8068\n",
            "Epoch 117/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8272 - val_loss: 0.4230 - val_accuracy: 0.8373\n",
            "Epoch 118/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8255 - val_loss: 0.4158 - val_accuracy: 0.8407\n",
            "Epoch 119/300\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8221 - val_loss: 0.4182 - val_accuracy: 0.8407\n",
            "Epoch 120/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8255 - val_loss: 0.4170 - val_accuracy: 0.8407\n",
            "Epoch 121/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8255 - val_loss: 0.4200 - val_accuracy: 0.8373\n",
            "Epoch 122/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8221 - val_loss: 0.4183 - val_accuracy: 0.8407\n",
            "Epoch 123/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8121 - val_loss: 0.4195 - val_accuracy: 0.8068\n",
            "Epoch 124/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8272 - val_loss: 0.4166 - val_accuracy: 0.8407\n",
            "Epoch 125/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8322 - val_loss: 0.4183 - val_accuracy: 0.8373\n",
            "Epoch 126/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8305 - val_loss: 0.4179 - val_accuracy: 0.8407\n",
            "Epoch 127/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8205 - val_loss: 0.4171 - val_accuracy: 0.8373\n",
            "Epoch 128/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8272 - val_loss: 0.4224 - val_accuracy: 0.8339\n",
            "Epoch 129/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8171 - val_loss: 0.4174 - val_accuracy: 0.8407\n",
            "Epoch 130/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8188 - val_loss: 0.4206 - val_accuracy: 0.8373\n",
            "Epoch 131/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8289 - val_loss: 0.4209 - val_accuracy: 0.8407\n",
            "Epoch 132/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8305 - val_loss: 0.4205 - val_accuracy: 0.8407\n",
            "Epoch 133/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8171 - val_loss: 0.4216 - val_accuracy: 0.8373\n",
            "Epoch 134/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8305 - val_loss: 0.4198 - val_accuracy: 0.8373\n",
            "Epoch 135/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8205 - val_loss: 0.4169 - val_accuracy: 0.8068\n",
            "Epoch 136/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8289 - val_loss: 0.4199 - val_accuracy: 0.8407\n",
            "Epoch 137/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8322 - val_loss: 0.4189 - val_accuracy: 0.8441\n",
            "Epoch 138/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8305 - val_loss: 0.4191 - val_accuracy: 0.8068\n",
            "Epoch 139/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8205 - val_loss: 0.4234 - val_accuracy: 0.8373\n",
            "Epoch 140/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8238 - val_loss: 0.4196 - val_accuracy: 0.8237\n",
            "Epoch 141/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8221 - val_loss: 0.4218 - val_accuracy: 0.8339\n",
            "Epoch 142/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8272 - val_loss: 0.4192 - val_accuracy: 0.8136\n",
            "Epoch 143/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8221 - val_loss: 0.4198 - val_accuracy: 0.8102\n",
            "Epoch 144/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8289 - val_loss: 0.4226 - val_accuracy: 0.8407\n",
            "Epoch 145/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8305 - val_loss: 0.4195 - val_accuracy: 0.8373\n",
            "Epoch 146/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8305 - val_loss: 0.4250 - val_accuracy: 0.8373\n",
            "Epoch 147/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8272 - val_loss: 0.4218 - val_accuracy: 0.8203\n",
            "Epoch 148/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8171 - val_loss: 0.4281 - val_accuracy: 0.8339\n",
            "Epoch 149/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8255 - val_loss: 0.4264 - val_accuracy: 0.8373\n",
            "Epoch 150/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8305 - val_loss: 0.4230 - val_accuracy: 0.8373\n",
            "Epoch 151/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8138 - val_loss: 0.4240 - val_accuracy: 0.8373\n",
            "Epoch 152/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8272 - val_loss: 0.4207 - val_accuracy: 0.8373\n",
            "Epoch 153/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8272 - val_loss: 0.4307 - val_accuracy: 0.8339\n",
            "Epoch 154/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8272 - val_loss: 0.4199 - val_accuracy: 0.8203\n",
            "Epoch 155/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.8272 - val_loss: 0.4292 - val_accuracy: 0.8305\n",
            "Epoch 156/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8238 - val_loss: 0.4217 - val_accuracy: 0.8441\n",
            "Epoch 157/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8305 - val_loss: 0.4258 - val_accuracy: 0.8373\n",
            "Epoch 158/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8305 - val_loss: 0.4254 - val_accuracy: 0.8373\n",
            "Epoch 159/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8305 - val_loss: 0.4236 - val_accuracy: 0.8373\n",
            "Epoch 160/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.8272 - val_loss: 0.4174 - val_accuracy: 0.8203\n",
            "Epoch 161/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8272 - val_loss: 0.4285 - val_accuracy: 0.8373\n",
            "Epoch 162/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8305 - val_loss: 0.4250 - val_accuracy: 0.8237\n",
            "Epoch 163/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8322 - val_loss: 0.4280 - val_accuracy: 0.8373\n",
            "Epoch 164/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8205 - val_loss: 0.4244 - val_accuracy: 0.8373\n",
            "Epoch 165/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8322 - val_loss: 0.4251 - val_accuracy: 0.8373\n",
            "Epoch 166/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8339 - val_loss: 0.4265 - val_accuracy: 0.8305\n",
            "Epoch 167/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8339 - val_loss: 0.4276 - val_accuracy: 0.8373\n",
            "Epoch 168/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8272 - val_loss: 0.4243 - val_accuracy: 0.8136\n",
            "Epoch 169/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8372 - val_loss: 0.4235 - val_accuracy: 0.8373\n",
            "Epoch 170/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8322 - val_loss: 0.4274 - val_accuracy: 0.8271\n",
            "Epoch 171/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8272 - val_loss: 0.4269 - val_accuracy: 0.8203\n",
            "Epoch 172/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8221 - val_loss: 0.4234 - val_accuracy: 0.8203\n",
            "Epoch 173/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8289 - val_loss: 0.4243 - val_accuracy: 0.8373\n",
            "Epoch 174/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8188 - val_loss: 0.4329 - val_accuracy: 0.8271\n",
            "Epoch 175/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8272 - val_loss: 0.4278 - val_accuracy: 0.8373\n",
            "Epoch 176/300\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8205 - val_loss: 0.4281 - val_accuracy: 0.8407\n",
            "Epoch 177/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8322 - val_loss: 0.4273 - val_accuracy: 0.8339\n",
            "Epoch 178/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8289 - val_loss: 0.4267 - val_accuracy: 0.8441\n",
            "Epoch 179/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8238 - val_loss: 0.4280 - val_accuracy: 0.8203\n",
            "Epoch 180/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8289 - val_loss: 0.4328 - val_accuracy: 0.8271\n",
            "Epoch 181/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8305 - val_loss: 0.4282 - val_accuracy: 0.8203\n",
            "Epoch 182/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8289 - val_loss: 0.4253 - val_accuracy: 0.8407\n",
            "Epoch 183/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8305 - val_loss: 0.4308 - val_accuracy: 0.8271\n",
            "Epoch 184/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8205 - val_loss: 0.4268 - val_accuracy: 0.8203\n",
            "Epoch 185/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8289 - val_loss: 0.4256 - val_accuracy: 0.8373\n",
            "Epoch 186/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8171 - val_loss: 0.4335 - val_accuracy: 0.8271\n",
            "Epoch 187/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8255 - val_loss: 0.4245 - val_accuracy: 0.8203\n",
            "Epoch 188/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8305 - val_loss: 0.4329 - val_accuracy: 0.8271\n",
            "Epoch 189/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8356 - val_loss: 0.4301 - val_accuracy: 0.8441\n",
            "Epoch 190/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8289 - val_loss: 0.4294 - val_accuracy: 0.8203\n",
            "Epoch 191/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8305 - val_loss: 0.4283 - val_accuracy: 0.8169\n",
            "Epoch 192/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8238 - val_loss: 0.4266 - val_accuracy: 0.8373\n",
            "Epoch 193/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8221 - val_loss: 0.4333 - val_accuracy: 0.8203\n",
            "Epoch 194/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8272 - val_loss: 0.4314 - val_accuracy: 0.8441\n",
            "Epoch 195/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8255 - val_loss: 0.4322 - val_accuracy: 0.8339\n",
            "Epoch 196/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8322 - val_loss: 0.4348 - val_accuracy: 0.8373\n",
            "Epoch 197/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8305 - val_loss: 0.4286 - val_accuracy: 0.8373\n",
            "Epoch 198/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8272 - val_loss: 0.4302 - val_accuracy: 0.8169\n",
            "Epoch 199/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8238 - val_loss: 0.4269 - val_accuracy: 0.8203\n",
            "Epoch 200/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8238 - val_loss: 0.4302 - val_accuracy: 0.8237\n",
            "Epoch 201/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8272 - val_loss: 0.4366 - val_accuracy: 0.8339\n",
            "Epoch 202/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8305 - val_loss: 0.4349 - val_accuracy: 0.8339\n",
            "Epoch 203/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8339 - val_loss: 0.4255 - val_accuracy: 0.8373\n",
            "Epoch 204/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8339 - val_loss: 0.4351 - val_accuracy: 0.8373\n",
            "Epoch 205/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8272 - val_loss: 0.4344 - val_accuracy: 0.8407\n",
            "Epoch 206/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8356 - val_loss: 0.4317 - val_accuracy: 0.8339\n",
            "Epoch 207/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8272 - val_loss: 0.4358 - val_accuracy: 0.8102\n",
            "Epoch 208/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8322 - val_loss: 0.4354 - val_accuracy: 0.8339\n",
            "Epoch 209/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8339 - val_loss: 0.4310 - val_accuracy: 0.8339\n",
            "Epoch 210/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8255 - val_loss: 0.4335 - val_accuracy: 0.8237\n",
            "Epoch 211/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8272 - val_loss: 0.4332 - val_accuracy: 0.8441\n",
            "Epoch 212/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8289 - val_loss: 0.4351 - val_accuracy: 0.8203\n",
            "Epoch 213/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8305 - val_loss: 0.4351 - val_accuracy: 0.8441\n",
            "Epoch 214/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8272 - val_loss: 0.4335 - val_accuracy: 0.8237\n",
            "Epoch 215/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8372 - val_loss: 0.4336 - val_accuracy: 0.8407\n",
            "Epoch 216/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8289 - val_loss: 0.4349 - val_accuracy: 0.8339\n",
            "Epoch 217/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8305 - val_loss: 0.4331 - val_accuracy: 0.8373\n",
            "Epoch 218/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8305 - val_loss: 0.4358 - val_accuracy: 0.8169\n",
            "Epoch 219/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8272 - val_loss: 0.4345 - val_accuracy: 0.8339\n",
            "Epoch 220/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8255 - val_loss: 0.4322 - val_accuracy: 0.8203\n",
            "Epoch 221/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8322 - val_loss: 0.4372 - val_accuracy: 0.8271\n",
            "Epoch 222/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8339 - val_loss: 0.4320 - val_accuracy: 0.8373\n",
            "Epoch 223/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8255 - val_loss: 0.4377 - val_accuracy: 0.8407\n",
            "Epoch 224/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8272 - val_loss: 0.4374 - val_accuracy: 0.8339\n",
            "Epoch 225/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8289 - val_loss: 0.4335 - val_accuracy: 0.8373\n",
            "Epoch 226/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8322 - val_loss: 0.4350 - val_accuracy: 0.8373\n",
            "Epoch 227/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8272 - val_loss: 0.4319 - val_accuracy: 0.8169\n",
            "Epoch 228/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8272 - val_loss: 0.4344 - val_accuracy: 0.8339\n",
            "Epoch 229/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8205 - val_loss: 0.4331 - val_accuracy: 0.8237\n",
            "Epoch 230/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8356 - val_loss: 0.4378 - val_accuracy: 0.8339\n",
            "Epoch 231/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8221 - val_loss: 0.4356 - val_accuracy: 0.8203\n",
            "Epoch 232/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8289 - val_loss: 0.4385 - val_accuracy: 0.8339\n",
            "Epoch 233/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8322 - val_loss: 0.4374 - val_accuracy: 0.8339\n",
            "Epoch 234/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8272 - val_loss: 0.4377 - val_accuracy: 0.8068\n",
            "Epoch 235/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8322 - val_loss: 0.4332 - val_accuracy: 0.8373\n",
            "Epoch 236/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8238 - val_loss: 0.4354 - val_accuracy: 0.8339\n",
            "Epoch 237/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8305 - val_loss: 0.4357 - val_accuracy: 0.8373\n",
            "Epoch 238/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8339 - val_loss: 0.4393 - val_accuracy: 0.8441\n",
            "Epoch 239/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8272 - val_loss: 0.4403 - val_accuracy: 0.8339\n",
            "Epoch 240/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8339 - val_loss: 0.4411 - val_accuracy: 0.8373\n",
            "Epoch 241/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8289 - val_loss: 0.4405 - val_accuracy: 0.8271\n",
            "Epoch 242/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8322 - val_loss: 0.4404 - val_accuracy: 0.8339\n",
            "Epoch 243/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8255 - val_loss: 0.4389 - val_accuracy: 0.8373\n",
            "Epoch 244/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8205 - val_loss: 0.4380 - val_accuracy: 0.8407\n",
            "Epoch 245/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8389 - val_loss: 0.4424 - val_accuracy: 0.8339\n",
            "Epoch 246/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8339 - val_loss: 0.4366 - val_accuracy: 0.8373\n",
            "Epoch 247/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8221 - val_loss: 0.4377 - val_accuracy: 0.8169\n",
            "Epoch 248/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8322 - val_loss: 0.4448 - val_accuracy: 0.8169\n",
            "Epoch 249/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8406 - val_loss: 0.4342 - val_accuracy: 0.8339\n",
            "Epoch 250/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8356 - val_loss: 0.4399 - val_accuracy: 0.8305\n",
            "Epoch 251/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8305 - val_loss: 0.4375 - val_accuracy: 0.8339\n",
            "Epoch 252/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8372 - val_loss: 0.4429 - val_accuracy: 0.8339\n",
            "Epoch 253/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8372 - val_loss: 0.4398 - val_accuracy: 0.8339\n",
            "Epoch 254/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8372 - val_loss: 0.4399 - val_accuracy: 0.8407\n",
            "Epoch 255/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8255 - val_loss: 0.4386 - val_accuracy: 0.8203\n",
            "Epoch 256/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8356 - val_loss: 0.4413 - val_accuracy: 0.8339\n",
            "Epoch 257/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8339 - val_loss: 0.4396 - val_accuracy: 0.8339\n",
            "Epoch 258/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8389 - val_loss: 0.4420 - val_accuracy: 0.8339\n",
            "Epoch 259/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8372 - val_loss: 0.4440 - val_accuracy: 0.8271\n",
            "Epoch 260/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8238 - val_loss: 0.4413 - val_accuracy: 0.8339\n",
            "Epoch 261/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8272 - val_loss: 0.4435 - val_accuracy: 0.8373\n",
            "Epoch 262/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.8339 - val_loss: 0.4386 - val_accuracy: 0.8339\n",
            "Epoch 263/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8272 - val_loss: 0.4407 - val_accuracy: 0.8237\n",
            "Epoch 264/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8339 - val_loss: 0.4403 - val_accuracy: 0.8339\n",
            "Epoch 265/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8372 - val_loss: 0.4443 - val_accuracy: 0.8339\n",
            "Epoch 266/300\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8322 - val_loss: 0.4441 - val_accuracy: 0.8339\n",
            "Epoch 267/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8372 - val_loss: 0.4403 - val_accuracy: 0.8407\n",
            "Epoch 268/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8322 - val_loss: 0.4433 - val_accuracy: 0.8271\n",
            "Epoch 269/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8255 - val_loss: 0.4427 - val_accuracy: 0.8237\n",
            "Epoch 270/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8339 - val_loss: 0.4454 - val_accuracy: 0.8339\n",
            "Epoch 271/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8289 - val_loss: 0.4419 - val_accuracy: 0.8136\n",
            "Epoch 272/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8272 - val_loss: 0.4465 - val_accuracy: 0.8339\n",
            "Epoch 273/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8305 - val_loss: 0.4401 - val_accuracy: 0.8203\n",
            "Epoch 274/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8255 - val_loss: 0.4464 - val_accuracy: 0.8305\n",
            "Epoch 275/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8356 - val_loss: 0.4448 - val_accuracy: 0.8271\n",
            "Epoch 276/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8289 - val_loss: 0.4421 - val_accuracy: 0.8339\n",
            "Epoch 277/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8356 - val_loss: 0.4408 - val_accuracy: 0.8339\n",
            "Epoch 278/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8372 - val_loss: 0.4412 - val_accuracy: 0.8407\n",
            "Epoch 279/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8356 - val_loss: 0.4476 - val_accuracy: 0.8169\n",
            "Epoch 280/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8289 - val_loss: 0.4470 - val_accuracy: 0.8339\n",
            "Epoch 281/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3744 - accuracy: 0.8339 - val_loss: 0.4484 - val_accuracy: 0.8339\n",
            "Epoch 282/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8322 - val_loss: 0.4445 - val_accuracy: 0.8339\n",
            "Epoch 283/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8221 - val_loss: 0.4436 - val_accuracy: 0.8102\n",
            "Epoch 284/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8322 - val_loss: 0.4467 - val_accuracy: 0.8339\n",
            "Epoch 285/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8205 - val_loss: 0.4446 - val_accuracy: 0.8407\n",
            "Epoch 286/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8389 - val_loss: 0.4454 - val_accuracy: 0.8305\n",
            "Epoch 287/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8305 - val_loss: 0.4431 - val_accuracy: 0.8373\n",
            "Epoch 288/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8289 - val_loss: 0.4453 - val_accuracy: 0.8339\n",
            "Epoch 289/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8289 - val_loss: 0.4459 - val_accuracy: 0.8237\n",
            "Epoch 290/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8339 - val_loss: 0.4500 - val_accuracy: 0.8237\n",
            "Epoch 291/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8322 - val_loss: 0.4460 - val_accuracy: 0.8339\n",
            "Epoch 292/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8322 - val_loss: 0.4475 - val_accuracy: 0.8339\n",
            "Epoch 293/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8289 - val_loss: 0.4502 - val_accuracy: 0.8034\n",
            "Epoch 294/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8356 - val_loss: 0.4464 - val_accuracy: 0.8305\n",
            "Epoch 295/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8356 - val_loss: 0.4482 - val_accuracy: 0.8339\n",
            "Epoch 296/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8356 - val_loss: 0.4473 - val_accuracy: 0.8339\n",
            "Epoch 297/300\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8322 - val_loss: 0.4500 - val_accuracy: 0.8305\n",
            "Epoch 298/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8322 - val_loss: 0.4530 - val_accuracy: 0.8237\n",
            "Epoch 299/300\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8339 - val_loss: 0.4461 - val_accuracy: 0.8169\n",
            "Epoch 300/300\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8305 - val_loss: 0.4497 - val_accuracy: 0.8305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faa2b839150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLQ7NkiojX7E"
      },
      "source": [
        "# Predicting on test data and submitting to kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "9gQpHpHMFgfq",
        "outputId": "db260fa5-f62d-4a13-9155-debecb50a4e8"
      },
      "source": [
        "test_prediction"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex   Age  SibSp  Parch\n",
              "0         3    male  34.5      0      0\n",
              "1         3  female  47.0      1      0\n",
              "2         2    male  62.0      0      0\n",
              "3         3    male  27.0      0      0\n",
              "4         3  female  22.0      1      1\n",
              "..      ...     ...   ...    ...    ...\n",
              "413       3    male   NaN      0      0\n",
              "414       1  female  39.0      0      0\n",
              "415       3    male  38.5      0      0\n",
              "416       3    male   NaN      0      0\n",
              "417       3    male   NaN      1      1\n",
              "\n",
              "[418 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "YyV0J8NBLX9g",
        "outputId": "abde82ff-b585-4db3-ba0d-e949e30021e2"
      },
      "source": [
        "X"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>is_child</th>\n",
              "      <th>Age</th>\n",
              "      <th>is_Alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346569</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  SibSp  Parch  Sex_male  is_child       Age  is_Alone\n",
              "0       3.0    1.0    0.0       1.0         0  0.271174         1\n",
              "1       1.0    1.0    0.0       0.0         0  0.472229         1\n",
              "2       3.0    0.0    0.0       0.0         0  0.321438         0\n",
              "3       1.0    1.0    0.0       0.0         0  0.434531         1\n",
              "4       3.0    0.0    0.0       1.0         0  0.434531         0\n",
              "..      ...    ...    ...       ...       ...       ...       ...\n",
              "886     2.0    0.0    0.0       1.0         0  0.334004         0\n",
              "887     1.0    0.0    0.0       0.0         0  0.233476         0\n",
              "888     3.0    1.0    2.0       0.0         0  0.346569         1\n",
              "889     1.0    0.0    0.0       1.0         0  0.321438         0\n",
              "890     3.0    0.0    0.0       1.0         0  0.396833         0\n",
              "\n",
              "[891 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "UramKm0QVgbu",
        "outputId": "5c764b40-6cf9-4d99-f2bf-c368bbff7dca"
      },
      "source": [
        "data"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex   Age  SibSp  Parch\n",
              "0         3    male  22.0      1      0\n",
              "1         1  female  38.0      1      0\n",
              "2         3  female  26.0      0      0\n",
              "3         1  female  35.0      1      0\n",
              "4         3    male  35.0      0      0\n",
              "..      ...     ...   ...    ...    ...\n",
              "886       2    male  27.0      0      0\n",
              "887       1  female  19.0      0      0\n",
              "888       3  female   NaN      1      2\n",
              "889       1    male  26.0      0      0\n",
              "890       3    male  32.0      0      0\n",
              "\n",
              "[891 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "rEqvGBKHVOp5",
        "outputId": "128e3cab-a50e-43b0-bdb5-1f3b6427db22"
      },
      "source": [
        "test_prediction"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass     Sex   Age  SibSp  Parch\n",
              "0         3    male  34.5      0      0\n",
              "1         3  female  47.0      1      0\n",
              "2         2    male  62.0      0      0\n",
              "3         3    male  27.0      0      0\n",
              "4         3  female  22.0      1      1\n",
              "..      ...     ...   ...    ...    ...\n",
              "413       3    male   NaN      0      0\n",
              "414       1  female  39.0      0      0\n",
              "415       3    male  38.5      0      0\n",
              "416       3    male   NaN      0      0\n",
              "417       3    male   NaN      1      1\n",
              "\n",
              "[418 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSwlYdt8Wkte",
        "outputId": "ab8e09ac-e66e-43a2-aa48-614cbf441f47"
      },
      "source": [
        "cat_cols"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sex']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqOo4xJYWmKH",
        "outputId": "934b7dfa-c6fb-438f-fb9a-98d8a07b8470"
      },
      "source": [
        "numerical_cols"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pclass', 'Age', 'SibSp', 'Parch']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GkYcI4PJNWc"
      },
      "source": [
        "\n",
        "test = pd.DataFrame(preprocessor.transform(test_prediction))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtGFAGXQYAXE"
      },
      "source": [
        "test.columns = numerical_cols1"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "tfR-YeD_YBQY",
        "outputId": "366c202d-7b7c-4b17-976e-932611d14e23"
      },
      "source": [
        "test"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_Female</th>\n",
              "      <th>Sex_male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>3.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass   Age  SibSp  Parch  Sex_Female  Sex_male\n",
              "0       3.0  34.5    0.0    0.0         0.0       1.0\n",
              "1       3.0  47.0    1.0    0.0         1.0       0.0\n",
              "2       2.0  62.0    0.0    0.0         0.0       1.0\n",
              "3       3.0  27.0    0.0    0.0         0.0       1.0\n",
              "4       3.0  22.0    1.0    1.0         1.0       0.0\n",
              "..      ...   ...    ...    ...         ...       ...\n",
              "413     3.0  28.0    0.0    0.0         0.0       1.0\n",
              "414     1.0  39.0    0.0    0.0         1.0       0.0\n",
              "415     3.0  38.5    0.0    0.0         0.0       1.0\n",
              "416     3.0  28.0    0.0    0.0         0.0       1.0\n",
              "417     3.0  28.0    1.0    1.0         0.0       1.0\n",
              "\n",
              "[418 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HVTpSKMYFoI"
      },
      "source": [
        "test = test.drop(['Sex_Female'],axis=1)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "tuYE7JJyYOIv",
        "outputId": "40a3c168-04c7-4bcd-9e40-2788578ade17"
      },
      "source": [
        "test"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>3.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass   Age  SibSp  Parch  Sex_male\n",
              "0       3.0  34.5    0.0    0.0       1.0\n",
              "1       3.0  47.0    1.0    0.0       0.0\n",
              "2       2.0  62.0    0.0    0.0       1.0\n",
              "3       3.0  27.0    0.0    0.0       1.0\n",
              "4       3.0  22.0    1.0    1.0       0.0\n",
              "..      ...   ...    ...    ...       ...\n",
              "413     3.0  28.0    0.0    0.0       1.0\n",
              "414     1.0  39.0    0.0    0.0       0.0\n",
              "415     3.0  38.5    0.0    0.0       1.0\n",
              "416     3.0  28.0    0.0    0.0       1.0\n",
              "417     3.0  28.0    1.0    1.0       1.0\n",
              "\n",
              "[418 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHAd9almYO1r"
      },
      "source": [
        "#test['is_Alone']= [1 if test['SibSp'][i]>0 or test['Parch'][i]>0 else 0 for i in test.index]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc5x8TJEYViV"
      },
      "source": [
        "test['is_child']= [1 if test['Age'][i]<16 else 0 for i in test.index]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "qQVKjVXPZcCo",
        "outputId": "186c5545-3a75-4928-99cc-bdfdd0ab9d42"
      },
      "source": [
        "test"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>is_child</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>3.0</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass   Age  SibSp  Parch  Sex_male  is_child\n",
              "0       3.0  34.5    0.0    0.0       1.0         0\n",
              "1       3.0  47.0    1.0    0.0       0.0         0\n",
              "2       2.0  62.0    0.0    0.0       1.0         0\n",
              "3       3.0  27.0    0.0    0.0       1.0         0\n",
              "4       3.0  22.0    1.0    1.0       0.0         0\n",
              "..      ...   ...    ...    ...       ...       ...\n",
              "413     3.0  28.0    0.0    0.0       1.0         0\n",
              "414     1.0  39.0    0.0    0.0       0.0         0\n",
              "415     3.0  38.5    0.0    0.0       1.0         0\n",
              "416     3.0  28.0    0.0    0.0       1.0         0\n",
              "417     3.0  28.0    1.0    1.0       1.0         0\n",
              "\n",
              "[418 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa5o3UM7Ygmo"
      },
      "source": [
        "age_fare = pd.DataFrame(scaler.transform(test[['Age']]))\n",
        "age_fare.columns = ['Age']"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u4rywK1YzWD"
      },
      "source": [
        "test = test.drop(['Age'],axis=1)\n",
        "frames = [test,age_fare]\n",
        "test = pd.concat(frames,axis=1)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uq3XhKWZDBl"
      },
      "source": [
        "test['is_Alone']= [1 if test['SibSp'][i]>0 or test['Parch'][i]>0 else 0 for i in test.index]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "g1CSIxwjZilN",
        "outputId": "658d0de3-568a-4d7b-a21a-edfdacab0545"
      },
      "source": [
        "X"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>is_child</th>\n",
              "      <th>Age</th>\n",
              "      <th>is_Alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346569</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  SibSp  Parch  Sex_male  is_child       Age  is_Alone\n",
              "0       3.0    1.0    0.0       1.0         0  0.271174         1\n",
              "1       1.0    1.0    0.0       0.0         0  0.472229         1\n",
              "2       3.0    0.0    0.0       0.0         0  0.321438         0\n",
              "3       1.0    1.0    0.0       0.0         0  0.434531         1\n",
              "4       3.0    0.0    0.0       1.0         0  0.434531         0\n",
              "..      ...    ...    ...       ...       ...       ...       ...\n",
              "886     2.0    0.0    0.0       1.0         0  0.334004         0\n",
              "887     1.0    0.0    0.0       0.0         0  0.233476         0\n",
              "888     3.0    1.0    2.0       0.0         0  0.346569         1\n",
              "889     1.0    0.0    0.0       1.0         0  0.321438         0\n",
              "890     3.0    0.0    0.0       1.0         0  0.396833         0\n",
              "\n",
              "[891 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "rlhi38BAZuao",
        "outputId": "daf4527d-86cd-487d-c4d5-91626431324a"
      },
      "source": [
        "test"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>is_child</th>\n",
              "      <th>Age</th>\n",
              "      <th>is_Alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.428248</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.585323</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.773813</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346569</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.484795</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.478512</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346569</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346569</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pclass  SibSp  Parch  Sex_male  is_child       Age  is_Alone\n",
              "0       3.0    0.0    0.0       1.0         0  0.428248         0\n",
              "1       3.0    1.0    0.0       0.0         0  0.585323         1\n",
              "2       2.0    0.0    0.0       1.0         0  0.773813         0\n",
              "3       3.0    0.0    0.0       1.0         0  0.334004         0\n",
              "4       3.0    1.0    1.0       0.0         0  0.271174         1\n",
              "..      ...    ...    ...       ...       ...       ...       ...\n",
              "413     3.0    0.0    0.0       1.0         0  0.346569         0\n",
              "414     1.0    0.0    0.0       0.0         0  0.484795         0\n",
              "415     3.0    0.0    0.0       1.0         0  0.478512         0\n",
              "416     3.0    0.0    0.0       1.0         0  0.346569         0\n",
              "417     3.0    1.0    1.0       1.0         0  0.346569         1\n",
              "\n",
              "[418 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jQddH6Wbpro",
        "outputId": "8df761a3-c614-481a-ee86-030b848f0654"
      },
      "source": [
        "logmodel.predict(test)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJogDrQPcZd3"
      },
      "source": [
        "p_test_prediction = test_prediction1['PassengerId']"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNNElNKGb9Xb"
      },
      "source": [
        "pred = pd.DataFrame({'PassengerId': p_test_prediction,'Survived': logmodel.predict(test)})"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZdRho2Jcd26"
      },
      "source": [
        "pred.to_csv('preds_log2.csv',index=False,header=1)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTsS_iRZbJm0",
        "outputId": "a2454915-a3ac-4feb-efea-ca07fb3d81b6"
      },
      "source": [
        "print('End')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}